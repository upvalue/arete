// vim: set ft=cpp

// compile-x64.cpp.dasc - Compile bytecode to native amd64 code
// This is a DynASM file. Must be run through DynASM to produce a C++ file

// Major todos

// DONE: Full closure support
// DONE: Allocate off of GC heap
// TODO: Extended argument functionality, VM primitives

#include <algorithm>
#include <functional>

#include "arete.hpp"

#if AR_64_BIT == 0

namespace arete {

void load_native_compiler(State&) {
}

}

#else

// Further reading
// Agner Fog, Calling Conventions
// http://www.agner.org/optimize/calling_conventions.pdf

// Hint: If it's crashing for no apparent reason, it's probably because the stack
// size is screwed up

// TODO: Tail call applications, how to do them in an efficent manner?
// Specifically, how to pass and preserve argv?

// TODO: Windows wants us to allocate space on the stack to return structs

// This discusses the Windows struct return issue, but doesn't
// seem to indicate why functions returning Value (only 64 bits) 
// seem to use a different calling convention
// https://msdn.microsoft.com/en-us/library/7572ztz4.aspx

// This seems to be limited to structs with constructors/destructors; a simple struct, even one with
// a union of pointer and ptrdiff_t, is returned in rax as it should be

// Whatever the reason for this, we need to follow the different struct
// calling conventions on Windows

// TODO: 
// Keep STATE in ARG1. Because all functions we call take State& as the first argument, this will
// remove the need for some MOV instructions. 

// TODO: GC frames can be trivially omitted in certain cases; if a function
// does not have upvalues, never calls other functions or allocation primitives

// A function like say, memv or assq might benefit heavily from this, but we'd probably need to
// inline recursive calls in the Scheme compiler in order to make it easy to determine whether this
// is possible here.

// TODO: Currently variables are GC-tracked much in the way we track them C++-side. But in assembly
// we have full control over the stack. Rather than using the NativeFrame structure, for example,
// we could just guarantee that everything from rsp to rsp+whatever is a pointer. One issue with the
// current approach vs VMFrames is that all stack values will be tracked while a function is live, 
// which means some garbage will remain. Imagine something like this being a memory leak:
// (let ()
//   ;; really complex computation that makes a big list
//   ;; main loop of a program that doesn't clear the stack
// )
// In practice, probably not a big deal. But worth changing if possible

// Could also just zero the stack when convenient

// TODO: Exception checking

// TODO: Function application
// TODO: Type checking
// TODO: Conditionals

// TODO: Serializability. Currently we're encoding function pointers directly in compiled code.

// TODO: We also may need to deal with C++ exceptions. Although we don't use them, we want to be
// able to call out to C++ code that may

// TODO: How to get stack traces out of this?
// Well, we know where the code_offset is at any given time, so we could store that in a register
// or on the stack and use it along with the VM source information to add stack trace info.

// Also, we only really need to store it at spots that can cause errors. Something like
// PUSH_IMMEDIATE will never fail.

// TODO: Register allocation

// Anatomy of a natively-compiled Scheme function

// Registers:
// STATE = r12 = pointer to arete::State*
// STACK = r13 = during execution, stores stack index.
// after control ends (due to exception or return), stores return value

// Stack:
// 0-8 = pointer to previous native stack frame (if any)
// 8-16 = count of gc'd values
// 16-a = computation stack
// a-b = local values
// b-c = upvalues

// Stack
// rsp+0 = pointer to previous stack frame
// rsp+8 = size_t count of gc'd values
// rsp+16 = vmfunction pointer
// rsp+24 = closure pointer (if any)
// rsp+32 = gc scratch for debugging purposes
// 32 - kUpvalueOffset = local variables
// kUpvalueOffset - kCompStackOffset = upvalues
// kCompStackOffset - rsp = computation stack

// TODO: Use offsetof and other stuff instead of calling functions to retrieve information
// about a particular State

// TODO: There is no need to store Closure pointer, we could store the VectorStorage of upvalues
// directly in the frame pointer

#include "dasm_proto.h"
#include "dasm_x86.h"

#define AR_LOG_JIT(msg) AR_LOG((AR_LOG_TAG_JIT), "jit", msg)

namespace arete {

static const bool dbg = false;
static const bool sanity_log = true;
static const bool gc_debug = true;

DefunGroup jit("jit");

///// A bunch of silly debugging code
Value state_make_pair(State* state) {
  Value pare(state->make_pair(C_FALSE, C_FALSE));
  std::cout << "state_make_pair returning " << (size_t) pare.bits << std::endl;
  return pare;
}

void state_collect(State* state) {
  std::cout << "COLLECTION BEGINNING " << (ptrdiff_t) state << std::endl;

  state->gc.collect();

  std::cout << "COLLECTION RETURNING" << std::endl;
}

static size_t vfn_ptr = 0;

void find_vfn_ptr(ptrdiff_t* rsp) {
	std::cout << (ptrdiff_t) rsp << std::endl;

	for(size_t i = 0; i != 20; i++) {
		ptrdiff_t p = rsp[i];
		std::cout << p << std::endl;
	}
}

ptrdiff_t rsp = 0;

Value simple_fn_pointer_check(State& state, size_t argc, Value* argv, void* fnp) {
	std::cout << (size_t) fnp << std::endl;
	return Value::make_fixnum((size_t) fnp);
}

void sanity_log_1(ptrdiff_t rsp_) {
  rsp = rsp_;
  std::cout << "sanity_log_1: rsp after stack allocation: " << rsp << std::endl;
}

void sanity_log_2(ptrdiff_t compstack) {
  std::cout << "sanity_log_2: location of computation stack[0]: " << compstack << "(" << (rsp - compstack) << " from rsp)" << std::endl;
}

void sanity_log_3(ptrdiff_t locals) {
  std::cout << "sanity_log_3: location of locals[0]: " << locals << "(" << (rsp - locals) << " from rsp)" << std::endl;
}

void sanity_log_4(ptrdiff_t vfn) {
  std::cout << "sanity_log_4 vfn: " << vfn << std::endl;
}

void sanity_log_5(ptrdiff_t argc) {
  std::cout << "sanity_log_5: argc: " << argc << std::endl;
}

void sanity_log_6(ptrdiff_t argv) {
  std::cout << "sanity_log_6: argv ptr: " << argv << std::endl;
}

static size_t vfn_bits = 0;

// Check that parameters have been properly extracted
void sanity_log_7(ptrdiff_t s, ptrdiff_t ac, ptrdiff_t av, void** rsp) {
  std::cout << "sanity_log_7 state: " << s << " argc: " << ac << " argv: " << av << " fn: " << (ptrdiff_t)rsp << std::endl;
}

void sanity_log_fourth_argument(void** rsp) {
	std::cout << "FOURTH:" << (size_t) rsp << std::endl;
	/*
	for(size_t i = 0; i != 12; i++) {
		std::cout << "[rsp+" << (i*8) << "] => " << (ptrdiff_t) rsp[i] << std::endl;
	}
	*/
}

void sanity_log_ret(ptrdiff_t STACK) {
  std::cout << "sanity_log_ret: STACK = " << STACK << std::endl;
}

void sanity_log_end(ptrdiff_t STACK) {
  std::cout << "sanity_log_end: return value = " << STACK << std::endl;
}

void print_stack_frame(NativeFrame* frame) {
  std::cout << "<<" << std::endl;;
  std::cout << "stack frame " << (ptrdiff_t) frame << std::endl;
  std::cout << "previous " << (ptrdiff_t) frame->previous << std::endl;
  std::cout << "count " << (ptrdiff_t) frame->value_count << std::endl;
  std::cout << "vmfunction " << (ptrdiff_t) frame->values[0].bits << std::endl;
  std::cout << "closure " << (ptrdiff_t) frame->values[1].bits << std::endl;
  std::cout << "scratch " << (ptrdiff_t) frame->values[2].bits << std::endl;
  for(size_t i = 3; i < frame->value_count; i++) {
    std::cout << "values[" << i << "]: " << (ptrdiff_t) frame->values[i].bits << std::endl;
  }
  std::cout << ">>" << std::endl;;
}

///// BELOW HERE: Functions which are actually needed for code to run properly

// Exception handling

// Because string munging in assembly is painful, exceptions are described by the NativeException
// struct and generated through an external C++ procedure

// Exception tag codes
enum {
  E_TYPE,
  E_EVAL
};

// Exception source codes
enum {
  E_UPVALUES_NOT_SUPPORTED,
  E_UPVALUE_CLOSED,
  E_UPVALUE_NATIVE,
  E_UPVALUE_VM,
  E_UNDEFINED,
  E_ARITY_CHECK_EQ,
  E_ARITY_CHECK_GTE,
  E_APPLY_CHECK,
  E_ADD,
  E_LT,
  E_SUB,
  E_FX_ADD,
  E_FX_SUB,
  E_FX_LT,
  E_CAR,
};

// Exception message codes
enum {
  E_EXPECTED_FIXNUM_1,
  E_EXPECTED_FIXNUM_2,
  E_EXPECTED_TYPE_1,
};


struct NativeException {
  State* state1;
  State* state;
  ptrdiff_t function1;
  size_t code_offset;
  ptrdiff_t tag;
  ptrdiff_t src;
  ptrdiff_t arg1;
  ptrdiff_t arg2;
};

/**
 * Function for generating an exception with a trace from a native function.
 */
ptrdiff_t native_throw_exception(NativeException* exc) {
	std::cout << sizeof(NativeException) << std::endl;
  std::cout << (ptrdiff_t) exc << std::endl;
  if(!exc) return C_FALSE;

  AR_LOG_JIT("!native_throw_exception called with state " << (ptrdiff_t) exc->state <<
    " VMFunction: " << exc->function1 << " code_offset: " << exc->code_offset
    << " tag: " << exc->tag << " src: " << exc->src << " arg1: " << exc->arg1
    << " arg2: " << exc->arg2);

	Value function(exc->function1);

  AR_ASSERT(function.type() == VMFUNCTION);

  std::ostringstream os;

  Value stag;

  if(exc->tag == E_TYPE) {
    stag = exc->state->globals[State::S_TYPE_ERROR];
  } else {
    stag = exc->state->globals[State::S_EVAL_ERROR];
  }

  bool check_code = true;
  switch(exc->src) {
    case E_UPVALUES_NOT_SUPPORTED: {
      check_code = false;
      os << "closures not supported :(";
      break;
    }

    case E_APPLY_CHECK: {
      check_code = false;
      os << "attempt to apply non-applicable value " << Value(exc->arg1);
      break;
    }

    case E_UNDEFINED: {
      check_code = false;
      os << "attempt to access undefined variable " << Value(exc->arg1);
      break;
    }

    case E_UPVALUE_NATIVE: check_code = false; os << "native upvalue"; break;
    case E_UPVALUE_CLOSED: check_code = false; os << "closed upvalue"; break;
    case E_UPVALUE_VM: {
      check_code = false;
      os << (size_t) exc->state->gc.vm_stack << " -> " << (size_t) exc->arg1 << std::endl;
      os << " !! vm upvalue";
      break;
    }

    case E_ARITY_CHECK_EQ: {
      check_code = false;
      os << "expected exactly " << exc->arg1 << " arguments but got " << exc->arg2;
      break;
    }
    case E_ARITY_CHECK_GTE: {
      check_code = false;
      os << "expected at least " << exc->arg1 << " arguments but got " << exc->arg2;
      break;
    }
    case E_FX_ADD: os << "primitive fx+ "; break;
    case E_FX_SUB: os << "primitive fx- "; break;
    case E_LT: {
      check_code = false;
      os << "primitive numeric comparison expected argument to be numeric but got " << Value(exc->arg1).type();
      break;
    }
    case E_SUB:
    case E_ADD: {
      check_code = false;
      os << "primitive arithmetic expected argument to be numeric but got " << Value(exc->arg1).type() << ": " << Value(exc->arg1);
      break;
    }
    case E_FX_LT: os << "primitive fx< "; break;
    case E_CAR: os << "primitive car "; break;
    default: break;
  }

  if(check_code) {
    switch(exc->arg1) {
      case E_EXPECTED_FIXNUM_1: os << "expected argument 1 to be a fixnum"; break;
      case E_EXPECTED_FIXNUM_2: os << "expected argument 2 to be a fixnum"; break;
      case E_EXPECTED_TYPE_1: os << "expected argument 1 to be a " << (Type) exc->arg2;
      default: break;
    }
  }

  std::cout << os.str() << std::endl;

  exc->state->trace_function(function, 0, exc->code_offset);
  
  return (ptrdiff_t)exc->state->make_exception(stag, os.str()).bits;
}

// callee-save

// parameters = rdi, rsi, rdx, rcx, r8, r9, xmm0-7
// rsp = stack pointer
// saved = rbx, rbp, rdi, rsi, rsp, r12-15
// rsp-128 is the red zone; can be used for temp values but destroyed by any called function

Value generic_apply(State* state, size_t argc, Value* argv, Value fn) {
  std::cout << "Generic_apply: " << (ptrdiff_t)state << ' ' << (ptrdiff_t) fn.bits <<
    ' ' << (ptrdiff_t) argc << ' ' << (ptrdiff_t) argv << std::endl;


  if(argc > 0) {
    std::cout << "argv[0] " << (ptrdiff_t) argv[0].bits << std::endl;
  }

  Value result(state->apply(fn, argc, argv));

  std::cout << state->get_symbol("print").symbol_value().bits << std::endl;

  return result;
}

/*
void* allocate_flonum(State* state, Flonum* flo) {
  std::cout << "Allocate flonum called with argument " << flo->number << std::endl;
  return (void*) state->make_flonum(flo->number).heap;
}
*/

void* allocate_flonum(State* state, double flo) {
  std::cout << "Allocate flonum called with argument " << (flo) << std::endl;
  return (void*) state->make_flonum(flo).heap;

}

void* allocate_rest_arguments(State* state, size_t arity, size_t argc, Value* argv) {
  // std::cout << "allocating rest arguments list " << (ptrdiff_t) state << " arity: " << arity << ' ' << "rest_argc_begin: " << (ptrdiff_t) argc << ' ' << (ptrdiff_t) argv << std::endl;

  AR_ASSERT(arity <= argc);

  state->temps.clear();
  for(size_t i = arity; i != argc; i++ ) {
    //std::cout << argv[i] << std::endl;
    state->temps.push_back(argv[i]);
  }

  return (void*) state->temps_to_list(0).bits;
}

struct NativeFrameSize {
  NativeFrame* previous;
  size_t value_count;
  Value closure;
  Value vmfunction;
  Value scratch;
};

void upvalue_close(State* state, Value upval) {
  //std::cout << "closing upvalue " << upval.bits <<  ' ' << upval.type() << std::endl;
  AR_ASSERT(state->gc.live(upval.heap));
  AR_ASSERT(upval.type() == UPVALUE);
  upval.upvalue_close();
}

size_t allocate_upvalue(State* state, Value* local) {
  Value upvalue = state->gc.allocate(UPVALUE, sizeof(Upvalue));
  upvalue.heap->set_header_bit(Value::UPVALUE_POINTER_BIT);
  upvalue.as_unsafe<Upvalue>()->U.local = local;
  AR_LOG_JIT("allocating upvalue " << upvalue.bits << " to stack location " << (size_t) local);

  return (size_t) upvalue.bits;

}

size_t make_closure(State* state, size_t upvalues, Value* stack_start) {
  Value storage, closure, vmf(stack_start[0]);
  AR_FRAME(*state, vmf, storage, closure, vmf);
  AR_LOG_JIT("make-closure upvalues: " << upvalues << " function: " << vmf);


  storage = state->make_vector_storage(upvalues);
  for(size_t i = 0; i != upvalues; i++) {
    state->vector_storage_append(storage, stack_start[1+i]);
    AR_ASSERT(stack_start[i+1].heap_type_equals(UPVALUE));
  }

  closure = state->gc.allocate(CLOSURE, sizeof(Closure));
  closure.as_unsafe<Closure>()->upvalues = storage.as<VectorStorage>();

  closure.as_unsafe<Closure>()->function = vmf;
  closure.procedure_install(vmf.as_unsafe<Procedure>()->procedure_addr);
  AR_ASSERT(closure.type() == CLOSURE);

  return closure.bits;
}

Value vmfunction_to_native(State& state, size_t argc, Value* argv, void* _) {
  const char* fn_name = "vmfunction->native";

  AR_FN_ARGC_GTE(state, argc, 1);
  AR_FN_ASSERT_ARG(state, 0, "to be a closure or vm function", argv[0].heap_type_equals(CLOSURE) || argv[0].heap_type_equals(VMFUNCTION));
  Value nfn, vfn, closure;

  closure = argv[0];
  vfn = closure.closure_unbox();

  AR_FRAME(state, nfn, vfn, closure);

  AR_LOG_JIT("vmfunction_to_native called");

  VMFunction* vmf = vfn.as_unsafe<VMFunction>();

  unsigned local_count = vmf->local_count;
  unsigned stack_max = vmf->stack_max;
  unsigned upvalue_count = vmf->upvalue_count;
  unsigned label = 0;

  // Using the otherwise not-used-in-this codebase kBlah style to denote things that will become
  // constants in the compiled code

  unsigned total_stack = local_count + stack_max + upvalue_count;
  unsigned kFrameValues = total_stack + 3;
  // Locals + computation stack + pointer to VMFunction and Closure and scratch

  size_t kFrameSize = sizeof(NativeFrameSize);
  // size_t kValueSize = sizeof(void*);

  // Stack frame offsets
  unsigned kLocalsOffset = (unsigned)kFrameSize;
  unsigned kUpvaluesOffset = (unsigned)(kFrameSize + (local_count * sizeof(void*)));
  unsigned kCompStackOffset = (unsigned)(kFrameSize + ((local_count + upvalue_count) * sizeof(void*)));

  unsigned kTotalStackSize = (unsigned)(kFrameSize + (total_stack * 8));
  unsigned kTotalStackSizeAligned = kTotalStackSize;

  if(!((kTotalStackSizeAligned % 16) != 0)) {
    kTotalStackSizeAligned += 8;
  }

#ifdef _MSC_VER
  kTotalStackSizeAligned += 8;
#endif

  AR_LOG_JIT("function frame info. stack_max " << stack_max << " kTotalStackSize " << kTotalStackSize << \
    " kTotalStackSizeAligned " << kTotalStackSizeAligned << " kLocalsOffset " << kLocalsOffset << 
    " kUpvaluesOffset " << kUpvaluesOffset << \
    " kCompStackOffset " << kCompStackOffset \
		<< " kFrameValues " << kFrameValues << " kFrameSize " << kFrameSize);

  // A note on a possible source of confusion: in the virtual machine, the stack is a separately
  // allocated data structure from locals and upvalues. Thus there's the computation stack which
  // exists only metaphorically here and is where the values of temporary computation are stored and
  // tracked by the garbage collector, and the actual stack i.e. rsp.

  | .arch x64
  |.section code

  |.define STATE, r12
  |.define STACK, r13
	|.if WINDOWS
	| .define ARG1, rcx
	| .define ARG2, rdx
  | .define ARG3, r8
  | .define ARG4, r9
	|.else
  | .define ARG1, rdi
  | .define ARG2, rsi
  | .define ARG3, rdx
  | .define ARG4, rcx
	|.endif
  |.type state, State, STATE

  // Defined separately in case calling conventions changed

  |.define sFramePrev, [rsp]
  |.define sFrameCount, [rsp+8]
  |.define sFrameFunction, [rsp+16]
  |.define sFrameClosure, [rsp+24]
  |.define sFrameScratch, [rsp+32]

  // Call a simple FUN, for debugging only.
  |.macro simpCall, fun
  | push ARG1; push ARG2; push ARG3; push ARG4;
	| .if WINDOWS
	// Allocate shadow space
	| push rbp; mov rbp, rsp; sub rsp, 32; mov64 rax, (ptrdiff_t) fun; call rax; add rsp, 32; mov rsp, rbp; pop rbp
	| .else
  | push rbp; push rsp; mov64 rax, (ptrdiff_t) fun; call rax; pop rsp; pop rbp;
	| .endif
  | pop ARG4; pop ARG3; pop ARG2; pop ARG1
  |.endmacro
  
  // Call without saving any registers
  | .macro callNoSave, fun
  | push rbp; push rsp; mov64 rax, (ptrdiff_t) fun; call rax; pop rsp; pop rbp
  | .endmacro
	//
  // Call a function which takes arete::State as its first argument
  |.macro stateCall, method
  | .if WINDOWS
  |  push rbp
  |  mov rbp, rsp
  |  mov ARG1, STATE
  |  mov64 rax, (ptrdiff_t) method
	|  sub rsp, 32
  |  call rax
	|  add rsp, 32
	|  mov rsp, rbp
  |  pop rbp
  | .else
  |  push rbp
  |  push rsp
  |  mov ARG1, STATE
  |  mov64 rax, (ptrdiff_t) method
  |  call rax
  |  pop rsp
  |  pop rbp
  | .endif
  |.endmacro

  // Check that value in STORE is a valid fixnum, if not, generate a type error with SRC and CODE
  // Generates a label
  |.macro checkFixnumP, store, src, code
  | test qword store, 1
  | jnz >1
  // Test failed. Set up registers for exception
  | throwNativeException E_TYPE, src, code, 0
  |1:
  |.endmacro

  |.macro checkFixnumPReg, store, src, code
  | test store, 1
  | jnz >1
  // Test failed. Set up registers for exception
  | throwNativeException E_TYPE, src, code, 0
  |1:
  |.endmacro

  |.macro checkNumberP, store, src, code
  |.endmacro

  |.macro assertHeapTypeEquals, store, src, code, tipe
  | test store, store
  | je >1
  | test store, 3
  | jz >2
  |1:
  | throwNativeException E_TYPE, src, E_EXPECTED_TYPE_1, tipe
  |2:
  |.endmacro

  // jmp to label >1 if value in STORE is immediate
  |.macro immediateJmpTo1, store
  // bits == 0 is #f
  | test store, store
  | je >1
  // bits & 3
  | test store, 3
  | jnz >1
  |.endmacro

  // Check whether a value in STORE is an exception and return it if so
  |.macro checkExceptionP, store
  | immediateJmpTo1 store
  | mov rax, [store]
  // quick exception check: we check for exception TYPE and 1 << 10 EXCEPTION_ACTIVE_BIT at once.
  | and rax, 2047
  | cmp rax, (EXCEPTION + Value::EXCEPTION_ACTIVE_BIT)
  | jne >1
  // this is an exception, return immediately
  | mov ARG3, code[current_insn]
  | mov STACK, store
  | jmp ->trace_exception
  |1:
  |.endmacro

  |.macro cmpHeapType, store, tipe
  | mov store, [store]
  | and store, 255
  | cmp store, tipe
  |.endmacro

  |.macro loadField, from, to, tname, fname
  | mov to, from
  | add to, ((ptrdiff_t)((&(tname*)0)->fname))
  | mov to, [to]
  |.endmacro

  // Check whether a value in STORE is applicable and extract its procedure address if so
  |.macro extractProcedureAddr, store
  // This is now guaranteed to be a heapvalue pointer, test it for VALUE_PROCEDURE_BIT
  | immediateJmpTo1 store
  | test qword [store], Value::VALUE_PROCEDURE_BIT
  | jnz >2
  | 1:
  | throwNativeException E_EVAL, E_APPLY_CHECK, store, 0
  | 2:
  | mov rax, store
  | add rax, (&((Procedure*)0)->procedure_addr)
  | mov rax, [rax]
  |.endmacro

  |.macro popStackTop, store
  | sub STACK, 8
  | mov store, STACK
  | mov store, [store]
  |.endmacro

  |.macro getStackTop, store
  | mov store, STACK
  | sub store, 8
  | mov store, [store]
  |.endmacro

  |.macro throwNativeException, tag, src, arg1, arg2
  // See also ->exception2:
  | sub rsp, sizeof(NativeException)
  | mov qword [rsp+24], (size_t) current_insn
  | mov qword [rsp+32], tag
  | mov qword [rsp+40], src
  | mov qword [rsp+48], arg1
  | mov qword [rsp+56], arg2
  | jmp ->exception
  |.endmacro

  // store a constant in a register
  |.macro storeConstant, reg, idx
  | mov ARG2, [rsp+16]
  // Get &VMFunction::constants
  | add ARG2, (ptrdiff_t)(&((VMFunction*)0)->constants)
  // Get &VMFunction->constants->data[idx]
  | mov ARG2, [ARG2]
  // Get VMFunction->constants->data[idx]
  | add ARG2, (ptrdiff_t)((((ptrdiff_t)&((VectorStorage*)0)->data)) + (idx * 8))
  | mov reg, [ARG2]
  |.endmacro

  |.macro incStack
  | add STACK, 8
  |.endmacro

  |.macro decStack
  | sub STACK, 8
  |.endmacro

  |.macro pushConstant, idx
  | storeConstant ARG2, idx
  | mov [STACK], ARG2
  | incStack
  |.endmacro

  dasm_State *d;
  dasm_init(&d, DASM_MAXSECTION);

  |.actionlist actions
  |.globals globals
  |.globalnames globalnames

  void* globals[globals_MAX == 0 ? 1 : globals_MAX];
  (void) globalnames; // suppress compiler warning

  dasm_setupglobal(&d, globals, globals_MAX);
  dasm_setup(&d, actions);

  dasm_State** Dst = &d;

  |.code
  // Prologue
  // Save registers
	| push rbp
  | mov rbp, rsp
  | push rbx
  | push STATE
  | push STACK
	|.if WINDOWS
	| push r14
	| push r15
	| mov STATE, ARG2
	|.else
  | mov STATE, ARG1
	|.endif

	// Get fourth argument off weird place in stack, thanks Windows.
	// 56 + (8*5) = register amount
	|.if WINDOWS
	// r14 = pointer to Closure/VMFunction
	| mov r14, [rsp+40+(8*6)]
	// r15 = location of return value on stack
	| mov r15, ARG1
	|.endif

  // NOTE: At the boundary of any CALL, stack size must be a multiple of 16!
  // PUSHing grows it by only 8.

  // Allocate stack space
  | sub rsp, kTotalStackSizeAligned

  // Get stack pointer
  | mov STACK, rsp
  | add STACK, kCompStackOffset

  // NativeFrame.values[0] = vfn
	|.if WINDOWS
	| mov qword sFrameFunction, r14
	|.else
  | mov sFrameFunction, ARG4
	|.endif
  // NativeFrame.values[1] = closure
  | mov qword sFrameClosure, 18
  | mov qword sFrameScratch, 18

	|.if WINDOWS
	// Windows, args have already been shifted because of screwed up calling convention
	//| mov ARG3, ARG4
	//| mov ARG4, r14
	|.else
  // Shuffle argc, argv into different registers so they can be processed in the function body
  // Shuffle argv into different register so we can use ARG2
  | mov ARG4, ARG3
  | mov ARG3, ARG2
	|.endif

  // Extract closure, if there is one

  // TODO: We know at compile time whether or not a VMFunction is a closure. Need to add a flag
  // or something so we don't emit this on non-closures
  | mov rax, sFrameFunction
  | mov rax, [rax]
  | and rax, 255
  | cmp rax, (CLOSURE)
  | jne ->past_closure_check

  | mov rax, sFrameFunction
  | mov sFrameClosure, rax

  | add rax, (&((Closure*)0)->function)
  | mov rax, [rax]
  | mov sFrameFunction, rax

  | ->past_closure_check:

  // NativeFrame.previous = state->gc.native_frames
  | mov ARG1, STATE
  | add ARG1, (ptrdiff_t)(&((arete::State*)0)->gc.native_frames)
  | mov ARG2, [ARG1]
  | mov sFramePrev, ARG2
  | mov [ARG1], rsp

  // TODO: Rather than MOVing STATE into ARG1, add offsets as necessary

  // Temporarily protect argv
  | mov ARG1, STATE
  | add ARG1, (ptrdiff_t)(&((arete::State*)0)->gc.protect_argc)
  | mov [ARG1], ARG3
  | mov ARG1, STATE
  | add ARG1, (ptrdiff_t)(&((arete::State*)0)->gc.protect_argv)
  | mov [ARG1], ARG4

  // NativeFrame.value_count
  | mov qword sFrameCount, kFrameValues

  if(dbg && sanity_log) {
    | mov ARG1, rsp
    | simpCall sanity_log_1

    | mov ARG1, sFrameFunction
    | simpCall sanity_log_4

    | mov ARG1, ARG3
    | simpCall sanity_log_5

    | mov ARG1, ARG4
    | simpCall sanity_log_6
  }

  // Zero out GC frame
  // Assumes function has a stack size of at least one.

  // TODO: Not necessary to zero out whole frame

  // Should be able to just zero out upvalues + computation stack. 
  // Locals (except rest) will be initialized before any collection

  // TODO: Except what if a function call causes an exception e.g. an arity error?
  // In that case, we should pop the native_frame off?

  | mov ARG1, rsp
  | add ARG1, kFrameSize
  // | add ARG1, kLocalsOffset + (vmf->max_arity * 8)

  | mov ARG2, rsp
  | add ARG2, kTotalStackSizeAligned

  | ->gc_zero:
  | mov qword [ARG1], 0
  | add ARG1, 8
  | cmp ARG1, ARG2
  | jne ->gc_zero

  if(upvalue_count) {
    for(size_t i = 0; i != upvalue_count; i++) {
      size_t idx = vmf->free_variables->bv_ref<size_t>(i);

      AR_LOG_JIT("allocating upvalue[" << i << "] from local idx " << idx);

      | mov ARG1, STATE
      | mov ARG2, rsp
      | add ARG2, (kLocalsOffset + (idx * 8))

      | push ARG3; push ARG4;
      | push rbp; push rsp;
      | mov64 rax, (size_t) allocate_upvalue; call rax
      | pop rsp; pop rbp;
      | pop ARG4; pop ARG3

      | mov ARG1, rsp
      | add ARG1, (kUpvaluesOffset + (i * 8))
      | mov [ARG1], rax
    }

    if(dbg) {
      | mov ARG1, rsp
      | simpCall print_stack_frame
    }

    //| throwNativeException 0, E_EVAL, E_UPVALUES_NOT_SUPPORTED, 0, 0
  }

  if(dbg) {
    | mov ARG1, rsp
    //| simpCall print_stack_frame
  }

  // Execute function body
  size_t code_offset = 0;
  size_t current_insn = 0;
  size_t *code = vmf->code_pointer();
  bool done = false;
  size_t code_limit = vmf->code->length;

  std::unordered_map<size_t, unsigned> offsets_to_labels;

  // Generate all labels

  // Generate labels
  while(true) {
    size_t loc = 0;

    if(code_offset == code_limit) {
      break;
    }

    switch(code[code_offset++]) {
      case OP_NOT:
      case OP_CAR:
      case OP_CDR:
      case OP_FX_ADD: case OP_FX_SUB: 
      case OP_FX_LT:
      case OP_POP:
      case OP_RETURN: 
      case OP_ARGV_REST:
      case OP_EQ: continue;

      case OP_APPLY:
      case OP_APPLY_TAIL:
      case OP_PUSH_IMMEDIATE:
      case OP_GLOBAL_GET:
      case OP_UPVALUE_GET:
      case OP_UPVALUE_SET:
      case OP_LOCAL_GET:
      case OP_LOCAL_SET:
      case OP_UPVALUE_FROM_LOCAL:
      case OP_UPVALUE_FROM_CLOSURE:
      case OP_CLOSE_OVER:
      case OP_ARGC_EQ:
      case OP_ARGC_GTE:
      case OP_PUSH_CONSTANT:
      case OP_ADD: case OP_SUB: case OP_LT:
        code_offset++; continue;

      case OP_GLOBAL_SET: code_offset += 2; continue;

      case OP_JUMP:
      case OP_JUMP_WHEN:
      case OP_JUMP_UNLESS:
      case OP_JUMP_WHEN_POP: {
        loc = code[code_offset++];
        break;
      }

      default: {
        AR_LOG_JIT("label generation unknown bytecode " << code[code_offset-1]);
        std::ostringstream os; os << "unknown bytecode during label generation " << code[code_offset-1];
        return state.eval_error(os.str());
      }
    }

    if(loc > 0){
      auto it = offsets_to_labels.find(loc);
      if(it == offsets_to_labels.end()) {
        unsigned lbl = label++;
        AR_LOG_JIT("code offset " << loc << " => label " << lbl);
        offsets_to_labels.insert(std::make_pair(loc, lbl));
      } else {
        AR_LOG_JIT("code offset " << loc << " == label " << it->second);
      }
    }
  }

  std::vector<size_t> offsets;
  for(auto it : offsets_to_labels) {
    offsets.push_back(it.first);
  }

  std::sort(offsets.begin(), offsets.end(), std::greater<size_t>());

  // Allocate space for labels
  dasm_growpc(&d, label);

  done = false;
  code_offset = 0;

  while(!done) {
    if(code_offset == code_limit) {
      break;
    }
    // Test for label generation
    if(offsets.size() > 0 && code_offset == offsets[offsets.size() - 1]) {
      auto i = offsets_to_labels.find(code_offset);
      unsigned lbl = i->second;
      offsets.pop_back();
      AR_LOG_JIT("generating label " << lbl << " for code offset " << code_offset);
      |=>lbl:
    }

    // Keep track of the current VM instruction
    // This is used to generate exception traces
    current_insn = code_offset;

    switch(code[code_offset++]) {
      case OP_PUSH_IMMEDIATE: {
        size_t value = code[code_offset++];
        AR_LOG_JIT("push-immediate " << Value(value) << " (" << (ptrdiff_t) value << ")");
        | mov qword [STACK], (size_t) value
        | add STACK, 8
        break;
      }

      case OP_PUSH_CONSTANT: {
        size_t idx = code[code_offset++];
        AR_LOG_JIT("push-constant " << idx);

        | pushConstant idx
        break;
      }

      case OP_POP: {
        AR_LOG_JIT("pop");
        | sub STACK, 8
        break;
      }

      case OP_GLOBAL_GET: {
        size_t idx = code[code_offset++];

        AR_LOG_JIT("global-get " << idx);

        | storeConstant ARG1, idx
        | add ARG1, (ptrdiff_t)(&(((Symbol*)0)->value))
        | mov ARG1, [ARG1]

        | cmp ARG1, (size_t)C_UNDEFINED
        | jne >1
        | storeConstant ARG1, idx
        | throwNativeException E_EVAL, E_UNDEFINED, ARG1, 0
        | 1:
        | mov [STACK], ARG1
        | incStack

        break;
      }

      case OP_LOCAL_GET: {
        size_t idx = code[code_offset++];
        size_t stack_offset = (kLocalsOffset + (8 * idx));
        AR_LOG_JIT("local-get " << idx << " at stack location " << stack_offset);

        | mov ARG1, rsp
        | add ARG1, stack_offset

        | mov ARG1, [ARG1]

        | mov [STACK], ARG1
   
        | incStack
        break;
      }

      case OP_LOCAL_SET: {
        size_t idx = code[code_offset++];
        size_t stack_offset = (kLocalsOffset + (8 * idx));
        AR_LOG_JIT("local-set " << idx << " at stack location " << stack_offset);

        | mov ARG1, rsp
        | add ARG1, stack_offset

        | popStackTop ARG2
        | mov [ARG1], ARG2

        break;
      }

      case OP_GLOBAL_SET: {
        size_t error_on_undefined = code[code_offset++];
        size_t idx = code[code_offset++];

        AR_LOG_JIT("global-set " << error_on_undefined << " " << idx);
        | storeConstant ARG1, idx
        | add ARG1, (ptrdiff_t)(&(((Symbol*)0)->value))

        | popStackTop ARG2
        | mov [ARG1], ARG2

        break;
      }

      case OP_UPVALUE_GET: {
        size_t idx = code[code_offset++];

        AR_LOG_JIT("upvalue-get " << idx);

        |.macro getUpvalue, store, idx
        | mov store, sFrameClosure
        | add store, (&((Closure*)0)->upvalues)
        | mov store, [rax]
        | add store, (ptrdiff_t)((((ptrdiff_t)&((VectorStorage*)0)->data)) + (idx * 8))
        | mov store, [rax]
        |.endmacro

        // Jumps to labels based on type of upvalue in rax
        // If upvalue is closed, jumps to >2
        // If upvalue is native, jumps to >1
        // If upvalue is VM, code immediately afterwards is executed
        |.macro upvalueDispatch
        | mov ARG1, [rax]
        | and ARG1, (Value::UPVALUE_CLOSED_BIT)
        | cmp ARG1, (Value::UPVALUE_CLOSED_BIT)
        | je >2
        | mov ARG1, [rax]
        | and ARG1, (Value::UPVALUE_POINTER_BIT)
        | cmp ARG1, (Value::UPVALUE_POINTER_BIT)
        | je >1
        |.endmacro

        |.macro extractUpvaluePointer
        | mov ARG2, rax
        | add ARG2, (ptrdiff_t)(&((Upvalue*)0)->U.local)
        //| mov ARG2, [ARG2]
        |.endmacro


        // TODO: This adds a LOT of code. 

        // Extract upvalue contents, which may either be a pointer, a stack offset, or a value
        // to be used immediately

        | getUpvalue rax, idx
        | extractUpvaluePointer
        | mov ARG2, [ARG2]
        | upvalueDispatch

        // The upvalue is an offset into the VM stack
        // Get pointer to VM stack
        | mov ARG1, STATE
        | add ARG1, (ptrdiff_t)(&((arete::State*)0)->gc.vm_stack)
        | mov ARG1, [ARG1]
        // Get offset of VM stack
        | imul ARG2, 8
        | add ARG1, ARG2
        | mov ARG1, [ARG1]
        | mov [STACK], ARG1
        | jmp >3
        | 1:
        | mov ARG2, [ARG2]
        | 2: 
        | mov [STACK], ARG2
        | 3: 

        | incStack

        break;
      }

      case OP_UPVALUE_SET: {
        size_t idx = code[code_offset++];
        AR_LOG_JIT("upvalue-set " << idx);

        | getUpvalue rax, idx
        | extractUpvaluePointer
        | decStack
        | mov ARG3, [STACK]
        | upvalueDispatch
        //
        // Get State::gc.vm_stack
        | mov ARG1, STATE
        | add ARG1, (ptrdiff_t)(&((arete::State*)0)->gc.vm_stack)
        | mov ARG1, [ARG1]
        // Get offset of VM stack
        | mov ARG2, [ARG2]
        | imul ARG2, 8
        | add ARG1, ARG2
        //| mov rax, [STACK]
        | mov [ARG1], ARG3
        | jmp >3
        | 1:
        // Native: pointer to pointer
        //| mov rax, [STACK]
        | mov ARG2, [ARG2]
        | mov [ARG2], ARG3
        | jmp >3
        | 2:
        // Upvalue is closed, this is a pointer
        //| mov rax, [STACK]
        | mov [ARG2], ARG3
        | 3: 
        //| throwNativeException 0, E_EVAL, E_UPVALUE_CLOSED, 0, 0


        break;
      }

      case OP_UPVALUE_FROM_CLOSURE: {
        size_t idx = code[code_offset++];

        AR_LOG_JIT("upvalue-from-closure " << idx);

        | mov ARG1, sFrameClosure
        | add ARG1, (&((Closure*)0)->upvalues)
        | mov ARG1, [ARG1]
        | add ARG1, (ptrdiff_t)((((ptrdiff_t)&((VectorStorage*)0)->data)) + (idx * 8))
        | mov ARG1, [ARG1]
        | mov [STACK], ARG1
        | incStack

        break;
      }

      case OP_UPVALUE_FROM_LOCAL: {
        size_t idx = code[code_offset++];

        AR_LOG_JIT("upvalue-from-local " << idx);

        | mov ARG1, rsp
        | add ARG1, (kUpvaluesOffset + (idx * 8))
        | mov ARG1, [ARG1]
        | mov [STACK], ARG1
        | incStack

        break;
      }

      case OP_CLOSE_OVER: {
        size_t upvalues = code[code_offset++];

        AR_LOG_JIT("make-closure " << upvalues);

        /*
        | mov ARG1, rsp
        | simpCall print_stack_frame
        */

        | mov ARG1, STATE
        | mov64 ARG2, (size_t) upvalues
        | mov ARG3, STACK
        // Stack position = stack - 8 - upvalues - 8 (for VMFunction at the beginning)
        | sub ARG3, (((size_t)((upvalues * 8) + 8)))
        | mov64 rax, (size_t) make_closure
        | call rax

        | sub STACK, (((size_t)((upvalues * 8) + 8)))
        | mov [STACK], rax
        | incStack


        break;
      }

      case OP_APPLY_TAIL: 
      case OP_APPLY: {
        size_t argc = code[code_offset++];

        AR_LOG_JIT("apply " << argc);

				|.if WINDOWS
				// Windows calling convention handling
				// We lose a register because ARG1 is used to communicate the address
				// of the return value
				| mov ARG2, STATE

				| mov ARG4, STACK
				| sub ARG4, ((argc * 8) + 8)

				| mov ARG4, [ARG4]

				| extractProcedureAddr ARG4

				// [rsp+0] location of return value
				// [rsp+8] location of function pointer
				// [8-48] not used

				| push rbp;
				| mov rbp, rsp;

				| sub rsp, 48

				| mov ARG4, STACK
				| sub ARG4, ((argc * 8) + 8)

				| mov ARG4, [ARG4]
				| mov [rsp+32], ARG4

				| mov ARG4, STACK
				| sub ARG4, ((argc * 8) + 8)
				| add ARG4, 8

				| mov ARG1, rsp
				| mov ARG3, (size_t) argc

				//| mov64 rax, (size_t) simple_fn_pointer_check
				| call rax

				| mov rax, [rsp]
				| mov [STACK], rax
				| incStack

				| add rsp, 48

				| mov rsp, rbp;
				| pop rbp

				|.else
        // Pointer to function on stack
        | sub STACK, ((argc * 8) + 8)

        // Pointer to argv, if there is one
        if(argc > 0) {
          | mov ARG3, STACK
          | add ARG3, 8
        }

        | mov ARG2, (size_t)argc
        | mov ARG1, STATE

        // Get pointer object from stack
        | mov ARG4, [STACK]

        // Type check and get Procedure::procedure_addr
        | extractProcedureAddr ARG4

        | call rax

        | mov ARG1, rax

        | checkExceptionP ARG1

        | mov [STACK], ARG1
        | incStack
				|.endif

        break;
      }

      case OP_JUMP: {
        size_t loc = code[code_offset++];
        AR_LOG_JIT("jump " << loc);

        auto it = offsets_to_labels.find(loc);
        AR_ASSERT(it != offsets_to_labels.end() && "jump label was not generated correctly");
        unsigned lbl = it->second;

        | jmp =>lbl
        break;
      }

      case OP_JUMP_WHEN:
      case OP_JUMP_UNLESS:
      case OP_JUMP_WHEN_POP: {
        size_t loc = code[code_offset++];
        // Get top of stack
        // If it is false, 

        auto it = offsets_to_labels.find(loc);
        AR_ASSERT(it != offsets_to_labels.end() && "jump label was not generated correctly");
        unsigned lbl = it->second;
        AR_LOG_JIT("jump-" << ((code[current_insn] == OP_JUMP_UNLESS) ? "unless" : "when") << ' ' << loc << " (label " << lbl << ")");

        if(code[current_insn] == OP_JUMP_WHEN_POP) {
          | popStackTop ARG1
        } else {
          | getStackTop ARG1
        }

        | cmp ARG1, C_FALSE
        if(code[current_insn] == OP_JUMP_UNLESS) {
          | jne =>lbl
        } else {
          | je =>lbl
        }
        break;
      }

      case OP_RETURN: {
        AR_LOG_JIT("return");
        | sub STACK, 8
        | mov STACK, [STACK]

        | jmp ->unwind

        break;
      }

      // Checking function arity

      case OP_ARGC_EQ:
      case OP_ARGC_GTE: {
        size_t fargc = code[code_offset++];

        | cmp ARG3, (size_t) fargc

        if(code[current_insn] == OP_ARGC_EQ) {
          | je >1
        } else if(code[current_insn] == OP_ARGC_GTE) {
          | jge >1
        }
        | throwNativeException E_EVAL, (code[current_insn] == OP_ARGC_EQ ? E_ARITY_CHECK_EQ : E_ARITY_CHECK_GTE), fargc, ARG3
        | 1:

        AR_LOG_JIT((code[current_insn] == OP_ARGC_EQ ? "argc-eq" : "argc-gte") << ' ' << fargc);

        // backup argv in r10 in case of rest arguments

        // Initialize local variables
        if(fargc) {
          AR_LOG_JIT("initializing locals with loop to " << kLocalsOffset + (8 * fargc));
          // ARG1 = &locals[0]
          | mov ARG1, rsp
          | add ARG1, (kLocalsOffset)
          // ARG2 = &argv[0]
          | mov ARG2, ARG4

          // limit = &locals[max_arity]
          | mov rax, ARG1
          | add rax, (8 * fargc)

          |->local_init:
          // mov argv[i] into r10
          | mov r10, [ARG2]
          // mov r10 into locals[i]
           | mov [ARG1], r10
          // Increment and check again
          | add ARG2, 8
          | add ARG1, 8
          | cmp ARG1, rax
          | jne ->local_init
        }

        if(dbg) {
          if(gc_debug) {
            //| stateCall state_collect;
          }
          | mov ARG1, rsp
          | simpCall print_stack_frame
        }

        | mov ARG2, (size_t) fargc
        
        | mov ARG1, STATE
        | add ARG1, (ptrdiff_t)(&((arete::State*)0)->gc.protect_argc)
        | mov qword [ARG1], 0

        break;
      }

      case OP_ARGV_REST: {
        AR_LOG_JIT("argv-rest");
        | mov ARG1, STATE
        | mov64 rax, (size_t)allocate_rest_arguments
        | call rax

        | mov ARG1, rsp
        | add ARG1, (kLocalsOffset + (vmf->max_arity * 8))
        | mov [ARG1], rax

        break;
      }

      case OP_EQ: {
        AR_LOG_JIT("eq");

        | decStack
        | mov ARG1, [STACK]
        | cmp ARG1, [STACK-8]
        | je >1
        | mov qword [STACK-8], C_FALSE
        | jmp >2
        | 1:
        | mov qword [STACK-8], C_TRUE
        | 2:

        break;
      }

      case OP_CAR:
      case OP_CDR: {
        bool car = code[current_insn] == OP_CAR;
        AR_LOG_JIT((car ? "car" : "cdr"));

        | mov rax, [STACK-8]

        | assertHeapTypeEquals rax, E_CAR, E_EXPECTED_TYPE, PAIR
        | add rax, (car ? (ptrdiff_t)(&((Pair*)0)->data_car) : (ptrdiff_t)(&((Pair*)0)->data_cdr))
        | mov rax, [rax]
        | mov [STACK-8], rax

        break;
      }

      case OP_NOT: {

        | mov ARG1, [STACK-8]
        | cmp ARG1, C_FALSE
        | je >1
        | mov qword [STACK-8], C_FALSE
        | jmp >2
        | 1:
        | mov qword [STACK-8], C_TRUE
        | 2:

        break;
      }

      // Fixnum boolean expressions
      case OP_FX_LT: {
        | decStack

        | mov ARG2, STACK

        | mov ARG1, STACK
        | sub ARG1, 8

        | mov ARG1, [ARG1]
        | mov ARG2, [ARG2]

        | checkFixnumPReg ARG2, E_FX_LT, E_EXPECTED_FIXNUM_2
        | checkFixnumPReg ARG1, E_FX_LT, E_EXPECTED_FIXNUM_1

        | decStack
        // Probably move this down
        | mov qword [STACK], C_FALSE
        | cmp ARG1, ARG2
        | jl >1
        | jmp >2
        | 1: 
        | mov qword [STACK], C_TRUE
        | 2:
        | incStack

        break;
      }

      // Fixnum arithmetic operations
      case OP_FX_ADD:
      case OP_FX_SUB: {
        unsigned src = 0;

        switch(code[current_insn]) {
          case OP_FX_ADD: src = E_FX_ADD; AR_LOG_JIT("fx+"); break;
          case OP_FX_SUB: src = E_FX_SUB; AR_LOG_JIT("fx-"); break;
        }

        | sub STACK, 8
        | mov ARG2, STACK

        // TODO: Why is the shifting necessary? It should be possible to add or subtract
        // two fixnum values and return them as-is

        | mov ARG1, ARG2
        | mov ARG2, [ARG2]

        // 2 labels: two for each type test
        | checkFixnumPReg ARG2, src, E_EXPECTED_FIXNUM_2

        // Extract fixnum argument 1 value
        | shr ARG2, 1

        // Get first stackvalu
        | sub ARG1, 8

        | mov rax, [ARG1]
        | checkFixnumPReg rax, src, E_EXPECTED_FIXNUM_1
        | shr rax, 1

        switch(code[current_insn]) {
          case OP_FX_ADD:
            | add rax, ARG2
            break;
          case OP_FX_SUB:
            | sub rax, ARG2
            break;
        }

        | shl rax, 1
        | inc rax

        | mov [ARG1], rax

        // set top of stack
        break;
      }

      case OP_LT: {
        size_t argc = code[code_offset++];
        size_t insn = code[current_insn];

        // TODO: Optimize redundant type checks.

        | mov ARG3, STACK
        | sub STACK, (argc * 8)

        | 1:
        | mov rax, [STACK]
        | test rax, 1
        | jz >2
        // Lhs is fixnum

        | mov ARG1, [STACK+8]
        | test ARG1, 1
        | jz >3
        // Lhs is fixnum and rhs is fixnum

        | cmp rax, ARG1
        if(insn == OP_LT) {
          | jl >7
        }
        | jmp >8

        | 2:
        // 2: Lhs is flonum or error
        | test rax, rax
        | je >9
        | test rax, 3
        | jnz >9
        | cmpHeapType rax, FLONUM
        | mov rax, [STACK]
        | jne >9

        // Lhs is flonum
        | add rax, (&((Flonum*)0)->number)
        | movsd xmm0, qword [rax]

        | mov rax, [STACK+8]
        | test rax, 1
        | jnz >4

        | test rax, rax
        | je >9
        | test rax, 3
        | jnz >9
        | cmpHeapType rax, FLONUM
        | mov rax, [STACK+8]
        | jne >9
        // Lhs is flonum and rhs is flonum

        | add rax, (&((Flonum*)0)->number)
        | movsd xmm1, qword [rax]

        | ucomisd xmm0, xmm1

        if(insn == OP_LT) {
          | jb >7
        }
        | jmp >8

        // 4: Lhs is flonum and rhs is fixnum
        | 4: 

        | shr rax, 1
        | cvtsi2sd xmm1, rax
        | ucomisd xmm0, xmm1

        if(insn == OP_LT) {
          | jb >7
        }

        | jmp >8

        // 3: Lhs is fixnum and rhs is flonum or error
        | 3: 

        | mov rax, [STACK+8]

        // Test for #f and other constants
        | test rax, rax
        | je >9
        | test rax, 3
        | jnz >9
        | cmpHeapType rax, FLONUM
        | mov rax, [STACK+8]
        | jne >9

        // Lhs is fixnum and rhs is flonum
        | mov ARG1, [STACK]
        | shr ARG1, 1
        | cvtsi2sd xmm0, ARG1

        //| mov rax, [STACK+8]
        | add rax, (&((Flonum*)0)->number)
        | movsd xmm1, qword [rax]
        | ucomisd xmm0, xmm1

        if(insn == OP_LT) {
          | jb >7
        }
        | jmp >8

        // Loop restart
        | 7:
        | add STACK, 16
        | cmp ARG3, STACK
        | je >7
        | sub STACK, 8
        | jmp <1

        // First 9: Exception
        | 9:
        | throwNativeException E_TYPE, E_LT, rax, 0

        // 7: Return true
        | 7:
        | mov ARG2, 2
        | jmp >9

        // 8: Return false
        | 8: 
        | mov ARG2, 0

        // Second 9: Fix stack and return
        | 9:
        | mov STACK, ARG3
        | sub STACK, ((argc) * 8)
        | mov [STACK], ARG2
        | incStack

        break;
      }

      case OP_ADD:
      case OP_SUB: {
        size_t argc = code[code_offset++];
        size_t insn = code[current_insn];
        
        if(insn == OP_ADD) {
          AR_LOG_JIT("add " << argc);
        } else if(insn == OP_SUB) {
          AR_LOG_JIT("sub" << argc);
        }

        if(argc == 0) {
          // No-argument plus (returns 0)
          | mov qword [STACK], Value::make_fixnum(0).bits
          break;
        } else if(argc == 1) {
          if(insn == OP_ADD) {
            // Unary plus (does nothing but return)
            break;
          } else if(insn == OP_SUB) {
            // Unary minus (negation)

            | mov rax, [STACK-8]

            | shr rax, 1
            | neg rax
            | shl rax, 1
            | inc rax

            | mov [STACK-8], rax

            break;
          }
        }

        // N-ary addition
        // ARG1 = current value
        // ARG2 = fixnum result accumulator
        // xmm0 = flonum result accumulator
        | mov ARG2, 0
        // ARG3 = loop limit 
        | mov ARG3, STACK

        //| mov rax, (insn == OP_ADD ? (argc * 8) : ((argc - 1) * 8))
        //| mov rax, (argc * 8)
        | sub STACK, (argc * 8)

        // Subtraction: initialize accumulator with first value
        if(insn == OP_SUB) {
          | mov ARG2, [STACK]
          | add STACK, 8
          | test ARG2, 1
          | jz >2
          // 1: Initialize accumulator with value
          | 1:
          | shr ARG2, 1
          | jmp >1
          // 2: Test for float
          | 2:
          | cmpHeapType ARG2, FLONUM
          | jne >6
          | mov ARG2, [STACK-8]
          | add ARG2, (ptrdiff_t)((&((Flonum*)0)->number))
          | movsd xmm0, qword [ARG2]
          | jmp >3
          //| loadField ARG1, [STACK], Flonum, number

        }

        // 1: Iterate over and add fixnum arguments
        |1:
        | mov ARG1, [STACK]
        // Check for fixnum, if not fixnum, break out of this loop and check for numeric types
        | test ARG1, 1
        | jz >2
        
        // This is a fixnum, add to accumulator
        | shr ARG1, 1

        if(insn == OP_SUB) {
          | sub ARG2, ARG1
        } else {
          | add ARG2, ARG1
        }

        // Increment loop and check again
        | add STACK, 8
        | cmp STACK, ARG3
        | jne <1

        // Fixnum addition succeeded, return
        | jmp >8

        // 2: Simple fixnum operation failed
        | 2: 
        // This is a flonum. Convert fixnum to flonum and continue
        | cvtsi2sd xmm0, ARG2
        // 3: Beginning of fixnum/flonum loop dispatch
        | 3: 
        | mov ARG1, [STACK]
        // Check for fixnum
        | test ARG1, 1
        | jnz >4
        // Check for non-fixnum constant or #f
        | test ARG1, ARG1
        | je >6
        | test ARG1, 3
        | jnz >6
        // Check for flonum
        | cmpHeapType ARG1, FLONUM
        | je >5

        // This is not a flonum, save the pointer and jump to exception
        | mov ARG1, [STACK]
        | jmp >6

        // Add flonum

        // 4: Add fixnum to flonum and continue
        | 4:

        | shr ARG1, 1
        | cvtsi2sd xmm1, ARG1

        if(insn == OP_ADD) {
          | addsd xmm0, xmm1
        } else if(insn == OP_SUB) {
          | subsd xmm0, xmm1
        }

        | add STACK, 8
        | cmp STACK, ARG3
        | jne <3
        // Finished adding, return floating point value
        | jmp >7

        // 5: Add flonum to flonum and continue
        | 5:

        | mov ARG1, [STACK]
        | add ARG1, (ptrdiff_t)(&((Flonum*)0)->number)
        | movsd xmm1, qword [ARG1]

        if(insn == OP_ADD) {
          | addsd xmm0, xmm1
        } else if(insn == OP_SUB) {
          | subsd xmm0, xmm1
        }

        | add STACK, 8
        | cmp STACK, ARG3
        | jne <3

        /*
        | mov ARG1, [STACK]
        | add ARG1, (ptrdiff_t)(&((Flonum*)0)->number)
        | movdqu xmm0, [ARG1]
        */
        //| mov ARG1, [ARG1]
        //| mov ARG1, 0
        //| movsd xmm0, qword ARG1

        | jmp >7

        // 6: Throw type exception
        | 6:
        | throwNativeException E_TYPE, E_ADD, ARG1, 0

        // 7: Allocate and return flonum result
        | 7:

        | mov rax, (size_t)(argc * 8)
        | sub STACK, rax

        | mov ARG1, STATE
        | mov64 rax, (size_t) allocate_flonum
        | call rax

        | mov [STACK], rax

        | jmp >9

        // 8: Return fixnum result
        | 8:

        | mov rax, (size_t)(argc * 8)
        | sub STACK, rax

        | shl ARG2, 1
        | inc ARG2
        | mov [STACK], ARG2

        //| mov [STACK], ARG1
        | 9:

        | incStack

        break;
      }


      default: {
        AR_LOG_JIT("unknown bytecode " << code[code_offset-1]);
        return state.eval_error("unknown bytecode");
      }
    }
  }

  | jmp ->unwind

  // Attempt to trace exception
  |->trace_exception:

  |jmp ->unwind

  |->exception:
	// Add State* and VMFunction pointer to this
	| mov ARG1, [rsp+(sizeof(NativeException)+16)]
  | mov qword [rsp+16], ARG1
	| mov qword [rsp+8], STATE
  | mov ARG1, rsp
	| sub rsp, 48
  | simpCall native_throw_exception
  | mov STACK, rax
	| add rsp, 48
  | add rsp, sizeof(NativeException) // Reset stack
  
  |->unwind: 

  // Protect return value
  if(dbg && gc_debug) {
    | mov sFrameScratch, STACK
    //| stateCall state_collect;
    | mov STACK, sFrameScratch
  }

  if(dbg && sanity_log) {
    | mov ARG1, STACK
    | simpCall sanity_log_end
  }

  // Close over local upvalues
  if(upvalue_count) {
    for(size_t i = 0; i != upvalue_count; i++) {
      | mov ARG2, rsp
      | add ARG2, (kUpvaluesOffset + (i * 8))
      | mov ARG2, [ARG2]
      
      | mov ARG1, STATE
      | mov64 rax, (size_t) upvalue_close
      | call rax
    }
  }

  // state->gc.native_frames = NativeFrame.previous
  | mov ARG1, STATE
  | add ARG1, (ptrdiff_t)(&((arete::State*)0)->gc.native_frames)
  | mov ARG2, [rsp]
  | mov [ARG1], ARG2

	| ->epilogue:

	//| mov ARG1, rsp
	//| simpCall find_vfn_ptr
	//| mov STACK, sFrameFunction

  // Free stack space
  | add rsp, kTotalStackSizeAligned

  // Retrieve return value from STACK

	// Windows requires us to allocate return space on the stack because Value is
	// a struct with a constructor
	| .if WINDOWS
	|  mov rax, rsp
	|  sub rax, 40
	|  mov [rax], STACK
	| .else
  |  mov rax, STACK
	| .endif

  // Restore registers
	|.if WINDOWS
	| pop r15
	| pop r14
	|.endif
  | pop STACK
	| pop STATE
  | pop rbx
  | mov rsp, rbp
	| pop rbp

  // Create return value
  | ret

  size_t size;

  dasm_link(&d, &size);

  char* proc_addr = (char*) state.allocate_native_code(size);

  AR_LOG_JIT("function size: " << size << "b vs " << (vfn.as_unsafe<VMFunction>()->code->size) << "b");

  dasm_encode(&d, proc_addr);

  dasm_free(&d);

  AR_LOG_JIT("vmfunction->native done; calling function");

	Value (*proc)(State*, size_t, Value*, void*) = ((Value (*)(State*, size_t, Value*, void*))(proc_addr));

  /*
	std::cout << "state pointer: " << (size_t) &state << std::endl;
	std::cout << "vfn bits : " << (size_t) vfn.bits << std::endl;

	vfn_ptr = vfn.bits;
	Value argvi[1] = {5};
	Value asdf  = proc(&state, 0, (Value*) argvi, (void*) vfn.bits);

	std::cout << "return value bits: " << Value(asdf) << std::endl;
  */

  if(!vfn.heap->get_header_bit(Value::VMFUNCTION_NATIVE_BIT)) {
    vfn.heap->set_header_bit(Value::VMFUNCTION_NATIVE_BIT);
  }

  // PROBLEM: A closure cannot have all procedure_addrs replaced in-place by the JIT compiler.

  vfn.as_unsafe<Procedure>()->procedure_addr = (c_closure_t)(void*)proc_addr;
  closure.as_unsafe<Procedure>()->procedure_addr = (c_closure_t)(void*)proc_addr;

  AR_ASSERT(vfn.procedurep());
  AR_ASSERT(closure.procedurep());

  return vfn;
}
AR_DEFUN("vmfunction->native!", vmfunction_to_native, 1);

Value fn_native_call(State& state, size_t argc, Value* argv, void* fn) {
  static const char* fn_name = "native-call";
  AR_FN_EXPECT_TYPE(state, argv, 0, VMFUNCTION); 

  AR_ASSERT(argv[0].heap->get_header_bit(Value::VMFUNCTION_NATIVE_BIT));

  Value vfn = argv[0];
  AR_FRAME(state, vfn);
  //AR_ASSERT(state.gc.live(vfn.as_unsafe<VMFunction>()->native_code));

  //Value bv(vfn.as_unsafe<VMFunction>()->native_code);

  if(dbg) {
    //std::cout << "Bv size: " << vfn.as_unsafe<VMFunction>()->native_code->size << std::endl;

    std::cout << "VMFunction ptr: " << (ptrdiff_t)vfn.bits << std::endl;
    std::cout << "Constants ref: " << (ptrdiff_t)&vfn.as<VMFunction>()->constants << std::endl;
    std::cout << "Constants ptr: " << (ptrdiff_t)vfn.as<VMFunction>()->constants << std::endl;
    std::cout << "Constants ptr[0]: " << (ptrdiff_t)&vfn.as<VMFunction>()->constants->data[0] << std::endl;

    std::cout << "#(";
    for(size_t i = 0; i != vfn.as<VMFunction>()->constants->length; i++) {
      std::cout << (ptrdiff_t)vfn.as<VMFunction>()->constants->data[i].bits;
      std::cout << ' ';
    }
    std::cout << ')' << std::endl;
    std::cout << "Calling against state: " << (ptrdiff_t) &state << std::endl;

    std::cout << " argc: " << argc-1 << " argv ptr: " << (size_t)argv+8 << std::endl;
  }

  // argc, argv, fn
	//void* fptr = (void*) vfn.as_unsafe<VMFunction>()->native_code->data;
  void *fptr = (void*) vfn.as_unsafe<VMFunction>()->procedure_addr;
  Value (*ptr)(State*, size_t, size_t, size_t) = (Value (*)(State*, size_t, size_t, size_t))(fptr);
  //Value result = ptr((State*) 12, (ptrdiff_t)34, (ptrdiff_t) 56, (ptrdiff_t) 78);
	vfn_bits = (size_t) vfn.bits;
	//for(size_t i= 0; i != 50; i++) { std::cout <<i<<std::endl;}
  Value result = ptr((State*) &state, argc-1, (size_t)argv+8, (size_t)vfn.bits);

  if(dbg) {
    std::cout << "result int: " << (ptrdiff_t)(result.bits) << std::endl;
    std::cout << "result: " << Value(result) << std::endl;

    std::cout << "state ptr: " << (ptrdiff_t)&state << std::endl;
    std::cout << "native_Frames: " << (ptrdiff_t)state.gc.native_frames << std::endl;
  }

  AR_ASSERT(state.gc.native_frames == 0);
  return result;
}
AR_DEFUN("native-call", fn_native_call, 1);

void load_native_compiler(State& state) {
  jit.install(state);
}

}

#endif // ARETE_64_BIT == 0




